% easychair.tex,v 3.5 2017/03/15

\documentclass{easychair}
%\documentclass[EPiC]{easychair}
%\documentclass[EPiCempty]{easychair}
%\documentclass[debug]{easychair}
%\documentclass[verbose]{easychair}
%\documentclass[notimes]{easychair}
%\documentclass[withtimes]{easychair}
%\documentclass[a4paper]{easychair}
%\documentclass[letterpaper]{easychair}

\usepackage{doc}
\usepackage{minted}

% use this if you have a long article and want to create an index
% \usepackage{makeidx}

% In order to save space or manage large tables or figures in a
% landcape-like text, you can use the rotating and pdflscape
% packages. Uncomment the desired from the below.
%
% \usepackage{rotating}
% \usepackage{pdflscape}

% Some of our commands for this guide.
%
\newcommand{\easychair}{\textsf{easychair}}
\newcommand{\miktex}{MiK{\TeX}}
\newcommand{\texniccenter}{{\TeX}nicCenter}
\newcommand{\makefile}{\texttt{Makefile}}
\newcommand{\latexeditor}{LEd}

%\makeindex

%% Front Matter
%%
% Regular title as in the article class.
%
\title{Meta-Reasoning in MeTTa for Inference Control via Provably
  Pruning the Search Tree}

% Authors are joined by \and. Their affiliations are given by \inst, which indexes
% into the list defined using \institute
%
\author{Nil Geisweiller}

% Institutes for affiliations are also joined by \and,
\institute{
  SingularityNET Foundation,\\
  Zug, Switzerland\\
  \email{nil@singularitynet.io}
}

%  \authorrunning{} has to be set for the shorter version of the authors' names;
% otherwise a warning will be rendered in the running heads. When processed by
% EasyChair, this command is mandatory: a document without \authorrunning
% will be rejected by EasyChair
\authorrunning{Geisweiller}

% \titlerunning{} has to be set to either the main title or its shorter
% version for the running heads. When processed by
% EasyChair, this command is mandatory: a document without \titlerunning
% will be rejected by EasyChair
\titlerunning{Meta Reasoning in MeTTa for Inference Control}

\begin{document}

\maketitle

\section{Methodology}
\label{sect:introduction}

How to speed-up reasoning by reasoning about reasoning?  This is the
question we will attempt to begin to answer in the context of a
meta-reasoning experiment described below.
\begin{enumerate}
\item A backward chainer is implemented in MeTTa~\cite{MeTTa} that
  takes in input a \emph{problem} theory (a set of rewriting rules), a
  query (a typing relationship containing holes) and outputs solutions
  in the form of the query with its holes filled.  By leveraging
  non-determinism and unification in MeTTa, a compact implementation
  is obtained, as evidenced by the code shown in
  Appendix~\ref{app:metta-backward-chainer}.
\item The backward chainer is then modified by inserting conditionals
  at every non-deterministic intersection, alongside user programmable
  contexts.  These conditionals are in charge of deciding whether to
  prune or to continue a particular path of the backward chainer.  The
  modified base case of the backward chainer is provided in
  Appendix~\ref{app:backward-chainer-continuation-conditionals} and
  the modified recursive step can be found under the Controlled
  Backward Chainer Section of ~\cite{Geisweiller2024ICM}.
\item \emph{Continuation} predicates associated to these conditionals
  are themselves defined as backward chainer calls over a
  \emph{control} theory, alongside a query formulating the question of
  whether to prune or to continue a particular branch.  Thus, at every
  step during problem solving, the backward chainer over the control
  theory is called.  If a proof of continuation is found, then the
  backward chainer over the problem theory is allowed to pursue its
  particular path, otherwise the branch is pruned.
\end{enumerate}

\section{Results}

The experiment is carried over a toy problem, the relationship of
precedence between the months of the year with a shortcut for the
month of January.  The control theory is simple and tailored toward
that particular problem only, by formalizing the January shortcut.
%% TODO: show rule.
%% Performances with and without inference control are
%% compared.
In that experiment the simplicity of the control theory allows to
obtain proofs of continuation at a small cost.  For that reason, the
performances with inference control are dramatically improved, ranging
from no speed-up to many-fold speed-ups depending on the difficulty of
the query.  More information about the experiment alongside its code
can be found in~\cite{Geisweiller2024ICM}.

%% This is the question we will begin to attempt answer in that paper.

%% Ways to inference control:
%% 1. Learn the continuation/termination predicate (classifier)
%% 2. Introspective reasoning
%% 2.1. Terminate/Continue type
%% 2.2. Cognitive schematics


%% By combining unification and non-determinism, MeTTa allows us to
%% implement in just a few lines of code a generic program and type
%% synthesizer capable of
%% 1. Synthesizing a program (or a proof) given its specification
%% 2. Infer the type of a program (or a proof)
%% 3. Partially fills holes in a program/proof or its type.

%% Non-determinism is a placeholder for any inference control policy.

\section{Related Work}

On the theoretical side, one ought to mention the work of J\"urgen
Schmidhuber on the G\"odel Machine~\cite{Schmidhuber2003}, a
self-improving machine powered at its center by an Automated Theorem
Prover (ATP) used to infer theorems expressing that a particular
rewrite may lead to increasing the expected reward.  In that paper,
J\"urgen mentions the possibility of using such machine to improve
theorem proving itself.  Worth mentioning is a survey of John Harrison
on metatheory and reflection in theorem
proving~\cite{Harrison1995MetatheoryAR}.  The survey is mostly
theoretical and more focused on correctness of meta-reasoning than
efficiency of inference.  Some practical ideas are mentioned
nonetheless such as inferring tactics that are correct by construction
and using formalism with explicit reflection.
%% Loosely
%% related, we have also found work on meta-reasoning in the context of
%% cognitive science and psychology, see~\cite{TODO} for a survey on the
%% matter.

On the practical side, finding work on meta-reasoning in the context
of ATP proved to be difficult.  A recent
survey~\cite{Blaauwbroek2024LearningGA} on applying AI techniques for
guiding ATP, citing over 150 papers, did not seem to mention any work
on meta-reasoning.  Additional Internet search did not seem to yield
more results.  We may of course have missed relevant work due to not
using the right terminology while searching.  Regardless, it indicates
that meta-reasoning in the context of ATP is likely under-explored and
deserves more attention than currently given.

\section{Conclusion and Future Work}

The work described in this document is only barely scratching the
surface.  Below are a few suggestions for future research.
\begin{enumerate}
\item The control theory should capture the notion of inference
  control more broadly as opposed to being hardwired to a specific
  problem.  This would allow to reuse the same control theory across
  multiple problems.
\item The control theory should be amenable to reason about empirical
  data.  In this manner, traces left by the backward chainer while
  attempting to solve problems could be used to infer predictive
  patterns about the likelihood of success of pursuing particular
  paths.  This could be done via inferential pattern
  mining~\cite{Geisweiller2019}, abstract reasoning, or combinations
  thereof by using an appropriate logic such as Probabilistic Logic
  Networks~\cite{Goertzel09PLN}.
\item The control theory should be so broad and applicable that it may
  benefit inference control over the control theory itself, which
  would open the possibility for creating virtuous feedback loops of
  meta-reasoning.
%% \item Meta-reasoning may be better modeled by process calculi, such as
%%   $\rho$-calculus~\cite{TODO} as opposed to traditional functional
%%   calculi, such as $\lambda$-calculus that primarily care about input
%%   and output types and not what occurs in between.
\end{enumerate}
%% What about reasoning about learning, from its most generic forms, such
%% as Solomonoff Induction~\cite{TODO}, to its most specialized forms,
%% such as XXX~\cite{TODO}?

%% Create a virtuous feedback loop

%------------------------------------------------------------------------------

\bibliographystyle{plain}
\label{sect:bib}
%\bibliographystyle{alpha}
%\bibliographystyle{unsrt}
%\bibliographystyle{abbrv}
\bibliography{MetaReasoningMeTTa}

%------------------------------------------------------------------------------
\appendix
\section{MeTTa Backward Chainer}
\label{app:metta-backward-chainer}

The backward chainer, \texttt{bc}, takes three arguments, a knowledge
base containing the theory \texttt{\$kb}, a query containing a typing
relationship between proof and theorem \texttt{(: \$prf \$thrm)}, and
a maximum depth.  It returns a non-deterministic superposition of
results, the query with its variables substituted by MeTTa terms
encoding wholes or parts of proofs and theorems.  It has two cases
\begin{enumerate}
\item Base case: the query directly matches an element of the
  knowledge base.
\item Recursive step: the query is divided into two sub-queries, one
  for finding a proof abstraction and another one for finding a proof
  argument applied to that proof abstraction.
\end{enumerate}
Unlike with traditional recursive algorithms, the base case and the
recursive step are non-deterministically competing with each other.
Also, in MeTTa the \texttt{let} operation corresponds to unification.
The code is provided below and more information can be found
in~\cite{Geisweiller2024ICM} \small{
\begin{minted}{scheme}
;; Base case
(= (bc $kb (: $prf $thrm) $_) (match $kb (: $prf $thrm) (: $prf $thrm)))
;; Recursive step
(= (bc $kb (: ($prfabs $prfarg) $thrm) (S $k))
   (let* (((: $prfabs (-> $prms $thrm)) (bc $kb (: $prfabs (-> $prms $thrm)) $k))
          ((: $prfarg $prms) (bc $kb (: $prfarg $prms) $k)))
     (: ($prfabs $prfarg) $thrm)))
\end{minted}
}

\section{Base Case with Continuation Conditionals}
\label{app:backward-chainer-continuation-conditionals}

The backward chainer is modified to take in inputs a \emph{control
structure}, a \emph{context}, in addition to a control theory and a
query.  A continuation conditional is placed at the entry of the base
case call, invoking \texttt{\$bcont} in order to determine whether to
continue or to prune the current branch.  Another conditional is
placed at the exit of the match query, invoking \texttt{\$mcont} to
determine whether to continue or to prune the current branch.  It is
important to have a conditional at the exit of the match query because
at that point more information is available to the continuation
predicate.  The built-in function \texttt{empty} is used to prune the
current branch.  The modified base case can be found below and more
information (including the modified recursive step) can be found
in~\cite{Geisweiller2024ICM}.  \small{
\begin{minted}{scheme}
;; Modified base case
(= (bc $kb                                               ; Knowledge base
       (MkControl $absupd $argupd $bcont $rcont $mcont)  ; Control
       $ctx                                              ; Context
       (: $prf $thrm))                                   ; Query
   ;; Base case continuation conditional
   (if ($bcont (: $prf $thrm) $ctx)
       ;; Continue by querying the kb
       (match $kb (: $prf $thrm)
              ;; Match continuation conditional
              (if ($mcont (: $prf $thrm) $ctx)
                  ;; Continue by returning the queried result
                  (: $prf $thrm)
                  ;; Terminate by pruning
                  (empty)))
       ;; Terminate by pruning
       (empty)))
\end{minted}
}

%------------------------------------------------------------------------------
\end{document}
