%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% AGI-22 paper about temporal and procedural reasoning with OpenCog %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bussproofs}
\usepackage{cite}

% For ⩘ and ⩗ (requires the LuaLaTeX engine)
\usepackage{unicode-math}
\setmathfont{Stix Two Math}

% Commands for Atomese code
\newcommand{\SP}{\;\;\;}
\newcommand{\TTrue}{\textit{True}}
\newcommand{\TFalse}{\textit{False}}
\newcommand{\TAtom}{\textit{Atom}}
\newcommand{\TTime}{\textit{Time}}
\newcommand{\TEval}{\textit{Evaluation}}
\newcommand{\TList}{\textit{List}}
\newcommand{\TLamb}{\textit{Lambda}}
\newcommand{\TExec}{\textit{Execution}}
\newcommand{\TAtTime}{\textit{AtTime}}
\newcommand{\TAnd}{\textit{And}}
\newcommand{\TOr}{\textit{Or}}
\newcommand{\TNot}{\textit{Not}}
\newcommand{\TImpl}{\textit{Implication}}
\newcommand{\TPredImpl}{\textit{PredictiveImplication}}
\newcommand{\TSeqAnd}{\textit{SequentialAnd}}
\newcommand{\TSeqOr}{\textit{SequentialOr}}
\newcommand{\TBSeqAnd}{\textit{BackSequentialAnd}}
\newcommand{\TFSeqAnd}{\textit{ForeSequentialAnd}}
\newcommand{\TLag}{\textit{Lag}}
\newcommand{\TLead}{\textit{Lead}}
\newcommand{\TTV}{\textit{TV}}
\newcommand{\TTVPo}{\textit{TV}_1^P}
\newcommand{\TTVQo}{\textit{TV}_1^Q}
\newcommand{\TTVPi}{\textit{TV}_i^P}
\newcommand{\TTVQi}{\textit{TV}_i^Q}
\newcommand{\TTVPn}{\textit{TV}_n^P}
\newcommand{\TTVQn}{\textit{TV}_n^Q}
\newcommand{\TTVP}{\textit{TV}^P}
\newcommand{\TTVQ}{\textit{TV}^Q}
\newcommand{\TTVR}{\textit{TV}^R}
\newcommand{\TTVPQ}{\textit{TV}^{PQ}}
\newcommand{\TTVQR}{\textit{TV}^{QR}}
\newcommand{\TBTV}{\langle \TTV \rangle}
\newcommand{\TBTVPo}{\langle \TTVPo \rangle}
\newcommand{\TBTVQo}{\langle \TTVQo \rangle}
\newcommand{\TBTVPi}{\langle \TTVPi \rangle}
\newcommand{\TBTVQn}{\langle \TTVQn \rangle}
\newcommand{\TBTVPn}{\langle \TTVPn \rangle}
\newcommand{\TBTVQi}{\langle \TTVQi \rangle}
\newcommand{\TBTVP}{\langle \TTVP \rangle}
\newcommand{\TBTVQ}{\langle \TTVQ \rangle}
\newcommand{\TBTVR}{\langle \TTVR \rangle}
\newcommand{\TBTVPQ}{\langle \TTVPQ \rangle}
\newcommand{\TBTVQR}{\langle \TTVQR \rangle}
\newcommand{\Tstrength}{\textit s}
\newcommand{\Tconf}{\textit c}

% Commands for symbolic mathematical notations
\newcommand{\sat}{\mathcal{Sat}}
\newcommand{\prob}{\mathcal{Pr}}
\newcommand{\limp}{\rightarrow}
\newcommand{\lpreimp}[1]{\leadsto^{#1}}
\newcommand{\lseqor}[1]{\bigslopedvee^{#1}}
\newcommand{\lseqand}[1]{\bigslopedwedge^{#1}}
\newcommand{\ldo}[1]{\widehat{#1}}
\newcommand{\llag}[2]{\overrightarrow{#1}^{#2}}
\newcommand{\llead}[2]{\overleftarrow{#1}^{#2}}
%% TODO: try to replace over right arrow by over right harp, etc
%% \newcommand{\llag}[2]{\accentset{\overrightharp}{#1}^{#2}}
%% \newcommand{\llead}[2]{\overleftharp{#1}^{#2}}

\newcommand{\ltrue}{\top}
\newcommand{\lfalse}{\bottom}

\begin{document}
%
\title{Temporal Probabilistic Logic Networks for Procedural Reasoning}

%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Nil Geisweiller
  %\orcidID{0000-0001-5041-6299}
  \and Hedra Yusuf}
%
\authorrunning{N. Geisweiller et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{ SingularityNET Foundation, The
  Netherlands\\ \email{\{nil,hedra\}@singularitynet.io}}
%
\maketitle              % typeset the header of the contribution
%

\begin{abstract}
  TODO

  \keywords{Temporal Reasoning \and Procedural Reasoning \and
    Probabilistic Logic Networks \and OpenCog}
\end{abstract}

\section{Introduction}

The goal of this project is to make an agent as rational as possible,
not necessarily as efficient as possible.  This stems from the concern
that in order to autonomously gain efficiency the agent must first be
able to make the best possible decisions, starting first in the outer
world, and then in the inner world.

% Inner actions could be as transitory as bringing a piece of
% knowledge to the attentional focus, and as profound as rewriting a
% part of its code, like a Goedel Machine.  The atomspace can be
% viewed as a very compact representation of an envelop over
% environments (cite partial operator induction paper).  And PLN can
% be viewed as an abstract-enabling way to calculate the cumulative
% reward (in case it is used as a re-inforcement learner) to be
% maximized, or a goal driven agent in a more general case.  For these
% reasons ROCCA may well be seen as an approximated combination of
% AI\Xi and a Goedel Machine.

The paper presents

The agent starts in a completely unknown environment

The idea is that reasoning is used at all levels, discovering patterns
from raw observations, building plans and making decisions.

It is a work in progress.

Neural networks are excellent at interpolation, but are rather poor at
extrapolation, what we need for true intelligence is a system that
thinks critically.

Rarely do causes and effects take place over arbitrary temporal
scales.  For instance it is unlikely to find a cause that may produce
the same effect, or an effect at all, after 1ms, 1 century or any time
in between.  For that reason we focus on a real time temporal logic.

% \section{Related Work}

% TODO: Event Calculus.  Temporal Logic (Next operator).  Subjective
% logic and evidence-based subjective logic.

% \section{Contributions}

% The contributions of this paper are:
% \begin{enumerate}
% \item Build upon existing temporal reasoning framework defined in
%   Chap.14 [TODO: cite PLN book].
% \item Design an architecture for controlling an agent based on that
%   temporal reasoning extension.
% \end{enumerate}

% \section{Outline}

% \begin{enumerate}
% \item Temporal reasoning
% \end{enumerate}

\section{Probabilistic Logic Networks Recall}

PLN stands for \emph{Probabilistic Logic
  Networks}~\cite{Goertzel09PLN}.  It is a mixture of predicate and
term logic that has been probabilitized to handle uncertainty.  It has
at least two types of rules for inferring relationships
\begin{enumerate}
\item from direct observations,
\item from existing relationships.
\end{enumerate}
As such it is well suited for building a model of a given environment,
and planning in that environment.  All it needs is to be properly
equipped with a vocabulary for representing temporal and procedural
knowledge.  The Chapter 14 of the PLN book~\cite{Goertzel09PLN} does
just that.  However we found that definitions are sometimes ambiguous
or incorrect.  This paper has been written to remedy that.

\subsection{Elementary Notions}

%% Let us first recall the minimum portion of PLN we will need to
%% describe the temporal logic used in this paper.

% ==========================================
%
% Random field => spatial reasoning
% Stochastic process => temporal reasoning
% |-
% Temporal index = any total order
% Spacial index = any topology
%
% TODO: express Allen's interval relations into TPLN
%
% ==========================================

% TODO: discuss emerging temporal reasoning from non temporal reasoning

Graphically speaking, PLN statements are
sub-hypergraphs\footnote{because links can point to links, not just
  nodes} made of \emph{Links} and \emph{Nodes}, called \emph{Atoms},
decorated with \emph{Truth Values}.  Syntactically speaking, PLN
statements are not very different from statements expressed in another
logic, except that they are usually formatted in prefixed-operator
with a tree-style indentation to emphasize their graphical nature and
to leave room for their truth values.  For instance
$$
\begin{array}{l}
  \TImpl\ \TBTV\\
  \SP P\\
  \SP Q\\
\end{array}
$$
represents an implication link between $P$ and $Q$ with truth value
$\TTV$.  For sake of conciseness we also adopt the following
representations.  We adopt a flattened, as opposed to a tree-style,
representation.  For instance the implication link above is
represented as
$$\TImpl(P, Q)\ \TBTV$$
We adopt a more mathematically looking symbolic representation.  For
instance that same implication can be represented as
$$P \limp Q \measeq \TTV$$
There is a large variety of constructs for PLN.  Here, we will focus
primarily on the ones for handling predicates.  Let us recall that
predicates are functions that output Boolean values.  The domain of a
predicate can be arbitrarily defined, but its range is always Boolean.
In this paper, the capital letters $A$, $B$, $C$ represent atoms of
any type, $X$, $Y$, $Z$ represent atoms that are variables, while $P$,
$Q$, $R$, $\dots$ represent atoms that are predicates, typed as follows:
% $$P, Q, R, \hdots: \TAtom^n \mapsto \{\TTrue, \TFalse\}$$
$$P, Q, R, \hdots: \textit{Domain} \mapsto \{\TTrue, \TFalse\}$$
Note that in PLN, predicates are not necessarily crisp because their
outputs can be totally or partially unknown, thus potentially
described by probabilities.

Truth values are, in essence, probability distributions of
probabilities, also called second order probability distributions.
They are often described by two numbers: a strength, $s$, representing
a probability, and a confidence, $c$, representing the confidence over
that probability.  Such truth values are called \emph{Simple Truth
  Values} and are denoted as follows
$$<\!s, c\!>$$
Alternatively, the strength and the confidence of a simple truth value
$\TTV$ can be denoted $\TTV.s$ and $\TTV.c$ respectively.  Underneath,
a simple truth value corresponds to a beta
distribution~\cite{Abourizk94Fitting} with parameters
$\alpha(s, c)=\alpha_0 + \frac{s.c.k}{1-c}$ and
$\beta(s, c)=\beta_0 + \frac{(1-s).c.k}{1-c}$, where $k$ is a PLN
parameter called the \emph{Lookahead}, and $\alpha_0$ and $\beta_0$
are usually set to 0.5 corresponding to Jeffreys prior.  For truth
values obtained from direct evidence, a simple truth value makes
perfect theoretical sense~\cite{TODO}.  For truth values obtained from
indirect evidence, not so much, even though they are often used in
practice.  When more precision is needed, to represent a multi-modal
truth value for instance, a mixture of simple truth values can be
used.  Through out the paper, sometimes we may say \emph{probability},
while what we really mean is \emph{second order probability
  distribution}.

% TODO: cite Subjective Logic and Chapt 4 of the PLN book.

% The constructs of interest covered in this paper are
% \begin{enumerate}
% \item $\TEval$ which can be used to define predicates from instances.
% \item $\TLamb$ which can be used to define predicates using
%   operational definitions.
% \item $\TAnd$, $\TOr$ and $\TNot$ which are pointwise counterparts of
%   the usual logical connectors.
% \item $\TImpl$ which can be used to define conditional predicates,
%   where their truth values represent conditional probabilities.
% \end{enumerate}

Below is a table of the constructs used in this paper with their
flattened and symbolic representations, as well as precedence to
minimize parenthesis usage when using the symbolic representation.
\renewcommand{\arraystretch}{1.5}
$$
\begin{array}{|c|c|c|}
  \hline
  \text{Flattened} & \text{Symbolic} & \text{Precedence} \\
  \hline
  % \TEval(P, \TList(X_1, \dots, X_n)) & P(X_1, \dots, X_n) & 0 \\
  \TEval(P, A) & P(A) & 0 \\
  % \TEval(P, \TList(X_1, \dots, X_n)) & P(X_1, \dots, X_n)=True & 0 \\
  \TNot(P) & \lnot P & 1 \\
  \TAnd(P, Q) & P \land Q & 2 \\
  \TOr(P, Q) & P \lor Q & 2 \\
  \TImpl(P, Q) & P \limp Q & 4 \\
  A \TBTV & A \measeq \TTV & 5 \\
  \hline
\end{array}
$$
\renewcommand{\arraystretch}{1}

For representing n-ary predicates one may use $P(A_1, \dots, A_n)$
which may simply be understood as unary predicates applied to tuples.
Let us now explain their semantics and how their truth values are
interpreted.
% The following uses unary predicates, n-ary predicates
% may be understood as unary predicates applied on tuples.
% especially as they each of them below with their corresponding truth
% values
% Let us present these operators below, corresponding to the minimum
% subset we will need in the rest of the paper.
\begin{itemize}
\item $\lnot P$ is the predicate resulting from the pointwise negation
  of $P$.
  % Negation:
  % $$
  % \begin{array}{l}
  %   \TNot\ \TBTV\\
  %   \SP P\\
  % \end{array}
  % $$
  % represents the negation of $P$, or equivalently the indicator
  % function corresponding to the complement of the satisfying set of
  % $P$. The truth value $\TTV$ then represents an estimate of
  % the probability $\prob(\neg P)$ of the negation of $P$.
\item
  % Conjunction:
  % $$
  % \begin{array}{l}
  %   \TAnd\ \TBTV\\
  %   \SP P\\
  %   \SP Q\\
  % \end{array}
  % $$
  $P \land Q$ is the predicate resulting from the pointwise
  conjunction of $P$ and $Q$.
  % , or equivalently the indicator function
  % corresponding to the intersection of the \emph{satisfying sets} of
  % $P$ and $Q$.  The truth value $\TTV$ then represents an estimate of
  % the probability $\prob(P,Q)$ of the conjunction of $P$ and $Q$.
\item
  % Conjunction:
  % $$
  % \begin{array}{l}
  %   \TAnd\ \TBTV\\
  %   \SP P\\
  %   \SP Q\\
  % \end{array}
  % $$
  $P \lor Q$ is the predicate resulting from the pointwise disjunction
  of $P$ and $Q$.
  % , or equivalently the indicator function
  % corresponding to the intersection of the \emph{satisfying sets} of
  % $P$ and $Q$.  The truth value $\TTV$ then represents an estimate of
  % the probability $\prob(P,Q)$ of the conjunction of $P$ and $Q$.
\item $P(A) \measeq \TTV$ states that $P(A)$ outputs $\TTrue$ with a
  second order probability described by $\TTV$.
  % Evaluation:
  % $$
  % \begin{array}{l}
  %   \TEval\ \TBTV\\
  %   \SP P\\
  %   \SP E\\
  % \end{array}
  % $$
  % states that $P(E)$ outputs $\TTrue$ to a degree set by the truth value
  % $\TTV$.
% \item Lambda:
%   $$
%   \begin{array}{l}
%     \TLamb\ \TBTV\\
%     \SP x\\
%     \SP P(x)\\
%   \end{array}
%   $$
%   is a predicate constructor with variable $x$ and predicate body
%   $P(x)$, where the true value $\TTV$ corresponds to the probability
%   $\prob(P)$ of $P(x)$ to output $\TTrue$ for a random input.
\item
  % Implication:
  % $$
  % \begin{array}{l}
  %   \TImpl\ \TBTV\\
  %   \SP P\\
  %   \SP Q\\
  % \end{array}
  % $$
  $P \limp Q \measeq \TTV$ states that if $P(A)$ is $\TTrue$ for some
  $A$ in the domain of $P$, then $Q(A)$ is $\TTrue$ with a second
  order probability described by $\TTV$.  In simple probability terms,
  it represents $\prob(Q|P)$~\footnote{To be precise, $\prob(Q|P)$
    should be understood as $\prob(\sat(Q)|\sat(P))$, where $\sat(P)$
    and $\sat(Q)$ are the satisfying sets of $P$ and $Q$
    respectively.}, the conditional probability of $Q$ knowing $P$.
  % represents the predicate $Q$ conditioned on $P$, that is
  % only defined for instances $x$ for which $P(x)$ is $\TTrue$.  The
  % truth value $\TTV$ then represents an estimate of the conditional
  % probability $\prob(Q|P)$.  There is some subtleties to take into
  % account due to the fact $P(x)$ can actually be partially true
  % (stated by the truth values of $\TEval$ links as explained above),
  % but this resolves nicely by assuming degrees of truth are
  % probabilistic.  More is explained about that below.
\item $P \measeq \TTV$ states that the prevalence of $P$ being
  $\TTrue$ is described by $\TTV$.
  % It is
  % equivalent to $\mathbb{True} \limp P \measeq \TTV$ where
  % $\mathbb{True}$ is the predicate that is $\TTrue$ for any input.
\end{itemize}

\subsection{Inference Rules}
Inferences rules are used to construct PLN statements and calculate
their truth values.  They fall into two groups, direct evidence based
or otherwise.  Rules from the former group infer abstract knowledge
from direct evidence, while rules from the latter group infer
knowledge by combining existing abstractions.  There are dozens of
inference rules, for now we only recall two, \emph{Implication Direct
  Introduction} and \emph{Deduction}.

\subsubsection{The Implication Direct Introduction Rule (IDI)} takes
evaluations
% $\TEval$
% links
as premises and produces an implication as conclusion.  It is formally
depicted by the following proof tree
% {\scriptsize
% \begin{prooftree}
%   \AxiomC{$
%     \begin{array}{l}
%       \TEval\ \TBTVPi\\
%       \SP P\\
%       \SP E_i\\
%     \end{array}
%     $}
%   \AxiomC{$\hdots$}
%   \AxiomC{$
%     \begin{array}{l}
%       \TEval\ \TBTVQi\\
%       \SP Q\\
%       \SP E_i\\
%     \end{array}
%     $}
%   \RightLabel{(IDI)}
%   \TrinaryInfC{$
%     \begin{array}{l}
%       \TImpl\ \TBTV\\
%       \SP P\\
%       \SP Q\\
%     \end{array}
%     $}
% \end{prooftree}}
{\small
\begin{prooftree}
  \AxiomC{$P(A_1) \measeq \TTVPo$}
  \AxiomC{$\hdots$}
  \AxiomC{$P(A_n) \measeq \TTVPn$}
  \RightLabel{(IDI)}
  \TrinaryInfC{$P\limp Q \measeq \TTV$}
\end{prooftree}}
\noindent Assuming perfectly reliable direct evidence\footnote{A
  perfectly reliable piece of evidence has a confidence of 1.  Dealing
  with unreliable evidence involves using convolution products and is
  outside of the scope of this paper.}  then the resulting simple
truth value can be calculated as follows
$$\TTV.\Tstrength = \frac{\sum_{i=1}^n f_\wedge(\TTVPi.\Tstrength,
  \TTVQi.\Tstrength)}{\sum_{i=1}^n \TTVPi.\Tstrength}\ \ \ \ \ \ \ \ \
\ \ \ \ \ \TTV.\Tconf = \frac{n}{n+k}$$
where % $\TTV.\Tstrength$ and
% $\TTV.\Tconf$ respectively represent the strength and the confidence
% of $\TTV$, $k$ is the lookahead, and
$f_\wedge$ is a function embodying a probabilistic assumption about
the conjunction of the events.  Such function typically ranges from
the product (perfect independence) to the $\min$ (perfect overlap).
Note that this inference rule takes an arbitrary number of premises.
In practice it is not a problem as it is decomposed into two rules
covering the base and the recursive cases, while storing evidence to
avoid double counting.

\subsubsection{The Deduction Rule (D)} takes two implications as
premises and produces a third one.  Depending on the assumptions made
there exists different variations of that rule.  The simplest one is
based on the Markov property % assuming that the probability of $R$
% knowing $P$ and $Q$ equals to the probability of $R$ knowing only $Q$.
$$\prob(R|Q,P) = \prob(R|Q)$$
%% $$\prob(R|\neg Q,P) = \prob(R|\neg Q)$$
which gives rise to the rule depicted by the following proof tree
{\small
  \begin{prooftree}
    \AxiomC{$P \limp Q \measeq \TTVPQ$}
    \AxiomC{$Q \limp R \measeq \TTVQR$}
    \AxiomC{$P \measeq \TTVP$}
    \AxiomC{$Q \measeq \TTVQ$}
    \AxiomC{$R \measeq \TTVR$}
    \RightLabel{(D)}
    \QuinaryInfC{$P \limp R \measeq \TTV$}
  \end{prooftree}
}
%%  essentially expressing a probabilitized version of the transitivity
%% of $\TImpl$ with a Markov property
%% $$\prob(R|Q,P) = \prob(R|Q)$$
%% $$\prob(R|\neg Q,P) = \prob(R|\neg Q)$$
\noindent The reader may notice that three additional premises have
been added, corresponding to the probabilities $\prob(P)$, $\prob(Q)$
and $\prob(R)$.  This is a consequence of the Markov property.  The
exact formula for that variation is not recalled here but it merely
derives from
$$\prob(R|P) = \prob(R|Q,P)\times\prob(Q|P) + \prob(R|\neg
Q,P)\times\prob(\neg Q|P)$$ More information about this derivation can
be found in Chapter 5, Section 5.3 of~\cite{Goertzel09PLN}.  Finally,
one may notice that the same conclusion may be inferred by different
inference paths leading to different truth values.  How to properly
aggregate these truth values is not the subject of this paper and is
discussed in Chapter 5, Section 5.10 of~\cite{Goertzel09PLN}.

\section{Temporal Probabilistic Logic Networks}

The temporal extension of PLN defined in~\cite{TODO} is somewhat
partial and ambiguous.  In that section we provide a possible
completion.
%% , showing how the two inference rules recalled
%% above to carry out temporal reasoning.  Let us define that
Let us begin by defining \emph{Temporal Predicates}, also called
\emph{Fluents} as predicates tends to denote atemporal relationships,
as regular predicates with a temporal dimension
$$P, Q, R, \hdots: \TAtom^n \times \TTime \mapsto \{\TTrue,
\TFalse\}$$ $\TTime$ here is considered discrete, formally defined as
a natural number.

\subsection{Temporal Operators}
Given temporal predicates we can now define a small set of temporal
operators.

\subsubsection{$\TLag$ and $\TLead$} are temporal operators to shift the
time dimension of a temporal predicate.  $\TLag$, respectively
$\TLead$, is similar to the metric variation of the \emph{Past}
operator denoted $P_n$, respectively the \emph{Future} operator
denoted $F_n$, of Temporal Logic \cite{Prior 1967, Chapter VI}, with
the distinction that it applies over an expression that evaluates into
a temporal predicate, as opposed to an expression that evaluates into
boolean.

The $\TLag$ operator is formally defined as follows
$$
\begin{array}{l}
  \TLag\\
  \SP P\\
  \SP T\\
\end{array}
$$
:=
$$
\begin{array}{l}
  \TLamb\\
  \SP x_1, ..., x_n, t\\
  \SP P(x_1, ..., x_n, t-T)\\
\end{array}
$$
where the first line of the $\TLamb$ link is the variable
declaration of the temporal predicate and the second line is the body
representing a temporally shifted reconstruction of $P$.  Informally
speaking, the $\TLag$ operator gives a peek into the past, or
equivalently, brings the past into the present.  This is a major
difference with \cite{PLN} that defined sequential and using notions
of the Event Calculus \cite{TODO}.  Here we do not do that (TODO:
maybe such operator should be called PrecedeAnd, or such).  That is
because using this simpler notion of sequential and allows more
flexibility to construct various forms of descriptions of how events
initialization, termination, etc, are sequenced.

The $\TLead$ operator is the inverse of the $\TLag$ operator and is
formally defined as follows
$$
\begin{array}{l}
  \TLead\\
  \SP P\\
  \SP T\\
\end{array}
$$
:=
$$
\begin{array}{l}
  \TLamb\\
  \SP x_1, ..., x_n, t\\
  \SP P(x_1, ..., x_n, t+T)\\
\end{array}
$$ As the inverse of the $\TLag$ operator, the $\TLead$ operator gives
a peek into the future, or equivalently, brings the future into the
present.  Finally, as being the inverse of one another, the following
equivalence holds
$$
\begin{array}{l}
  \TLag\\
  \SP \TLead\\
  \SP \SP P\\
  \SP \SP T\\
  \SP T\\
\end{array}
\equiv
\begin{array}{l}
  P\\
\end{array}
$$

\subsubsection{$\TSeqAnd$} is a temporal conjunction where one of the
temporal predicate arguments have been temporally shifted.  There are
two variations one can define.  A $\TBSeqAnd$ variation where the past
of one of the temporal predicates is brought into the present, using the
$\TLag$ operator, formally defined as
$$
\begin{array}{l}
  \TBSeqAnd\\
  \SP T\\
  \SP P\\
  \SP Q\\
\end{array}
:=
\begin{array}{l}
  \TAnd\\
  \SP \TLag\\
  \SP \SP P\\
  \SP \SP T\\
  \SP Q\\
\end{array}
$$
resulting into a temporal predicate such that in order to be true
at time $t$ requires that $P$ be true at time $t$ and $Q$ be true at
time $t+T$.

Inversely, there is a $\TFSeqAnd$ variation where the future of the
other temporal predicate is brought into the present, formally defined
as
$$
\begin{array}{l}
  \TFSeqAnd\\
  \SP T\\
  \SP P\\
  \SP Q\\
\end{array}
:=
\begin{array}{l}
  \TAnd\\
  \SP P\\
  \SP \TLead\\
  \SP \SP Q\\
  \SP \SP T\\
\end{array}
$$
resulting into a temporal predicate such that in order to be true
at time $t$ requires that $P$ be true at time $t-T$ and $Q$ be true at
time $t$.

Finally one may notice that $\TBSeqAnd$ and $\TFSeqAnd$ equivalent up
to temporal shifting, as follows

NEXT
$$
\begin{array}{l}
  \TBSeqAnd\\
  \SP T\\
  \SP P\\
  \SP Q\\
\end{array}
\equiv
\begin{array}{l}
  \TBSeqAnd\\
  \SP T\\
  \SP P\\
  \SP Q\\
\end{array}
$$

\subsubsection{$\TPredImpl$} likewise defines a temporal implication,
formally
$$
\begin{array}{l}
  \TPredImpl\\
  \SP T\\
  \SP P\\
  \SP Q\\
\end{array}
$$
:=
$$
\begin{array}{l}
  \TImpl\\
  \SP P\\
  \SP \TLead\\
  \SP \SP Q\\
  \SP \SP T\\
\end{array}
$$
resulting into a conditional predicate, that in order to be defined at
time $t$ requires that $P$ be true at time $t$, and in order to be true
at $t$ requires that $Q$ be true at $t+T$.

We now have everything we need to define temporal inference rules, but
before that let us first introduce some notations in order to be
easier to lay out.

\subsection{Notations}

The following notations can afford to ignore truth values, that is
because no new formula is required for temporal reasoning.  All that
is required are the definitions above mapping temporal expressions
into equivalent atemporal ones.  The notations are summarized in the
table below, ranked by syntactic precedence to minimize the number of
required parenthesis.
\renewcommand{\arraystretch}{1.5}
$$
\begin{array}{|c|c|c|}
  \hline
  \text{Atomese} & \text{Notation} & \text{Precedence} \\
  \hline
  \TEval(P, \TList(X_1, \dots, X_n)) & P(X_1, \dots, X_n) & 1 \\
  \TLamb(t, \TAtTime(\TExec(A), t)) & \ldo{A} & 1 \\
  \TLag(P, T) & \llag{P}{T} & 1 \\
  \TLead(P, T) & \llead{P}{T} & 1 \\
  \TAnd(P, Q) & P \land Q & 2 \\
  \TOr(P, Q) & P \lor Q & 2 \\
  \TSeqAnd(T, P, Q) & P \lseqand{T} Q & 3 \\
  \TSeqOr(T, P, Q) & P \lseqor{T} Q & 3 \\
  \TImpl(P, Q) & P \limp Q & 4 \\
  \TPredImpl(T, P, Q) & P \lpreimp{T} \! \! Q & 4 \\
  \TPredImpl(T, P, Q) & P \lpreimp{T} \! \! Q & 4 \\
  \hline
\end{array}
$$
\renewcommand{\arraystretch}{1}
The precedence of everything else (predicates nodes, etc) is 0.

%% Note that, assuming a ForeSequentialAnd, whether it is right or left
%% associative, changes whether the lag should be cumulative or not.
%%
%% Right-associative:
%% C∧A₁≺ᵀA₂≺ᵁA₃
%% C∧A₁≺ᵀ(A₂≺ᵁA₃)
%% C∧A₁∧Lead(A₂≺ᵁA₃, T)
%% C∧A₁∧Lead(A₂∧Lead(A₃, U), T)
%% C∧A₁∧Lead(A₂,T)∧Lead(A₃,T+U)
%%
%% Left-associative:
%% C∧A₁≺ᵀA₂≺ᵁA₃
%% (C∧A₁≺ᵀA₂)≺ᵁA₃
%% C∧A₁∧Lead(A₂,T)≺ᵁA₃
%% C∧A₁∧Lead(A₂,T)∧Lead(A₃,U)
%%
%% Assuming a BackSequentialAnd, it is the opposite

For instance

%% $$
%% \begin{array}{l}
%%   \TPredImpl\ \TBTV\\
%%   \SP \TSeqAnd\\
%%   \SP
%%   \SP E\\
%% \end{array}
%% $$

TODO: show examples of notational format with the effect of precedence

\subsection{Temporal Rules}

TODO: $\TPredImpl$ direct introduction.

Given that we can now introduce our temporal rules, (PI), (IP), (S)

TODO: detail (PI), (IP), (S) rules

and the most important one Temporal Deduction (TD)
{\small
  \begin{prooftree}
    \AxiomC{$P \lpreimp{T_1} Q$}
    \AxiomC{$Q \lpreimp{T_2} R$}
    \AxiomC{$P$}
    \AxiomC{$Q$}
    \AxiomC{$R$}
    \RightLabel{(TD)}
    \QuinaryInfC{$P \lpreimp{T_1+T_2} R$}
  \end{prooftree}
}
To determine the formula to calculate the resulting truth value of
such rule, we only need to map such temporal deduction into a regular
deduction as follows

{\tiny
  \begin{prooftree}
    \AxiomC{$P \lpreimp{T_1} Q$}
    \RightLabel{(PI)}
    \UnaryInfC{$P \limp \llead{Q}{T_1}$}
    \AxiomC{$Q \lpreimp{T_2} R$}
    \RightLabel{(PI)}
    \UnaryInfC{$Q \limp \llead{R}{T_2}$}
    \RightLabel{(S)}
    \UnaryInfC{$\llead{Q}{T_1} \limp \llead{R}{T_1+T_2}$}
    \AxiomC{$P$}
    \AxiomC{$Q$}
    \RightLabel{(S)}
    \UnaryInfC{$\llead{Q}{T_1}$}
    \AxiomC{$R$}
    \RightLabel{(S)}
    \UnaryInfC{$\llead{R}{T_1+T_2}$}
    \RightLabel{(D)}
    \QuinaryInfC{$P \limp \llead{R}{T_1+T_2}$}
    \RightLabel{(IP)}
    \UnaryInfC{$P \lpreimp{T_1+T_2} R$}
\end{prooftree}}

\subsection{Procedural Reasoning}

Likewise, we can use the same temporal to regular deduction mapping to
build inference rules for procedural reasoning.  Given two cognitive
schematics
$$P \land \ldo{A} \lpreimp{T_1} Q$$
expressing that executing $A$ in context $P$ likely leads to context
$Q$ after $T_1$ time units, and
$$Q \land \ldo{B} \lpreimp{T_2} R$$
expressing that executing $B$ in context $Q$ likely leads to context
$R$ after $T_2$ time units, the question becomes how to infer the
likelihood that executing $A$ and $B$ in sequence starting from
context $P$ leads to context $R$ after $T_1+T_2$ time units,
corresponding to the cognitive schematic
$$P \land \ldo{A} \lseqand{T_1} \ldo{B} \lpreimp{T_1+T_2} R$$

Using the same rules to map $\TPredImpl$ to regular $\TImpl$ and vice
versa, as well as rules about the $\TLead$ operator, we can construct
the following inference tree, in fact the PLN engine can construct it
for us

{\tiny
  \begin{prooftree}
    \AxiomC{$P\!\land\!\ldo{A} \lpreimp{T_1} Q$}
    \RightLabel{(PI)}
    \UnaryInfC{$P\!\land\!\ldo{A} \limp^{T_1} \llead{Q}{T_1}$}
    \RightLabel{(C)}
    \UnaryInfC{$P\!\land\!\ldo{A}\!\land\!\llead{\ldo{B}}{T_1} \limp
      \llead{Q}{T_1}\!\land\!\llead{\ldo{B}}{T_1}$}
    \AxiomC{$Q\!\land\!\ldo{B} \lpreimp{T_2} R$}
    \RightLabel{(PI)}
    \UnaryInfC{$Q\!\land\!\ldo{B} \limp \llead{R}{T_2}$}
    \RightLabel{(S)}
    \UnaryInfC{$\llead{Q}{T_1}\!\land\!\llead{\ldo{B}}{T_1} \limp
      \llead{R}{T_1+T_2}$}
    %% \AxiomC{$P\!\land\!\ldo{A}$}
    %% \AxiomC{$\llead{\ldo{B}}{T_1}$}
    %% \RightLabel{(C)}
    \AxiomC{$P\!\land\!\ldo{A}\!\land\!\llead{\ldo{B}}{T_1}$}
    \AxiomC{$Q\!\land\!\ldo{B}$}
    \RightLabel{(S)}
    \UnaryInfC{$\llead{Q}{T_1}\!\land\!\llead{\ldo{B}}{T_1}$}
    \AxiomC{$R$}
    \RightLabel{(S)}
    \UnaryInfC{$\llead{R}{T_1+T_2}$}
    \RightLabel{(D)}
    \QuinaryInfC{$P\!\land\!\ldo{A}\!\land\!\llead{\ldo{B}}{T_1} \limp \llead{R}{T_1+T_2}$}
    \RightLabel{(IP)}
    \UnaryInfC{$P\!\land\!\ldo{A}\!\lseqand{T_1}\!\ldo{B} \lpreimp{T_1+T_2} R$}
\end{prooftree}}
which reduces to the following inference tree after retaining only the
premises and the conclusion
{\tiny
  \begin{prooftree}
    \AxiomC{$P\!\land\!\ldo{A} \lpreimp{T_1} Q$}
    \AxiomC{$Q\!\land\!\ldo{B} \lpreimp{T_2} R$}
    \AxiomC{$P\!\land\!\ldo{A}\!\land\!\llead{\ldo{B}}{T_1}$}
    \AxiomC{$Q\!\land\!\ldo{B}$}
    \AxiomC{$R$}
    \RightLabel{(ASD)}
    \QuinaryInfC{$P\!\land\!\ldo{A}\!\lseqand{T_1}\!\ldo{B} \lpreimp{T_1+T_2} R$}
\end{prooftree}}
providing an Action Sequence Deduction (ASD) rule ready to be used for
procedural reasoning.  Three additional premises have been added
$P\!\land\!\ldo{A}\!\land\!\llead{\ldo{B}}{T_1}$, $Q\!\land\!\ldo{B}$
and $R$.

\section{Conclusion}

TODO: implement more temporal and procedural rules, support temporal
intervals, behavior trees, introduce Temporal Truth Value.  Integrate
Event Calculus.

Hint regarding intervals: define a notion of parameterized union,
where for temporal interval the parameters would be temporal variables
ranging over intervals.

%
% ---- Bibliography ----
%
\bibliographystyle{splncs04} \bibliography{local}

\end{document}
