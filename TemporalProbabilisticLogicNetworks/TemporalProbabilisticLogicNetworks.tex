%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% AGI-22 paper about temporal and procedural reasoning with OpenCog %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bussproofs}
\usepackage{cite}

% For ⩘ and ⩗ (requires the LuaLaTeX engine)
\usepackage{unicode-math}
\setmathfont{Stix Two Math}

% Commands for Atomese code
\newcommand{\SP}{\;\;\;}
\newcommand{\TTrue}{\textit{True}}
\newcommand{\TFalse}{\textit{False}}
\newcommand{\TAtom}{\textit{Atom}}
\newcommand{\TTime}{\textit{Time}}
\newcommand{\TEval}{\textit{Evaluation}}
\newcommand{\TList}{\textit{List}}
\newcommand{\TLamb}{\textit{Lambda}}
\newcommand{\TExec}{\textit{Execution}}
\newcommand{\TAtTime}{\textit{AtTime}}
\newcommand{\TAnd}{\textit{And}}
\newcommand{\TOr}{\textit{Or}}
\newcommand{\TNot}{\textit{Not}}
\newcommand{\TImpl}{\textit{Implication}}
\newcommand{\TPredImpl}{\textit{PredictiveImplication}}
\newcommand{\TSeqAnd}{\textit{SequentialAnd}}
\newcommand{\TSeqOr}{\textit{SequentialOr}}
\newcommand{\TBSeqAnd}{\textit{BackSequentialAnd}}
\newcommand{\TFSeqAnd}{\textit{ForeSequentialAnd}}
\newcommand{\TLag}{\textit{Lag}}
\newcommand{\TLead}{\textit{Lead}}
\newcommand{\TTV}{\textit{TV}}
\newcommand{\TTVo}{\textit{TV}_1}
\newcommand{\TTVi}{\textit{TV}_i}
\newcommand{\TTVn}{\textit{TV}_n}
\newcommand{\TTVPo}{\textit{TV}_1^P}
\newcommand{\TTVQo}{\textit{TV}_1^Q}
\newcommand{\TTVPi}{\textit{TV}_i^P}
\newcommand{\TTVQi}{\textit{TV}_i^Q}
\newcommand{\TTVPn}{\textit{TV}_n^P}
\newcommand{\TTVQn}{\textit{TV}_n^Q}
\newcommand{\TTVP}{\textit{TV}^P}
\newcommand{\TTVQ}{\textit{TV}^Q}
\newcommand{\TTVR}{\textit{TV}^R}
\newcommand{\TTVPQ}{\textit{TV}^{PQ}}
\newcommand{\TTVQR}{\textit{TV}^{QR}}
\newcommand{\TBTV}{\langle \TTV \rangle}
\newcommand{\TBTVPo}{\langle \TTVPo \rangle}
\newcommand{\TBTVQo}{\langle \TTVQo \rangle}
\newcommand{\TBTVPi}{\langle \TTVPi \rangle}
\newcommand{\TBTVQn}{\langle \TTVQn \rangle}
\newcommand{\TBTVPn}{\langle \TTVPn \rangle}
\newcommand{\TBTVQi}{\langle \TTVQi \rangle}
\newcommand{\TBTVP}{\langle \TTVP \rangle}
\newcommand{\TBTVQ}{\langle \TTVQ \rangle}
\newcommand{\TBTVR}{\langle \TTVR \rangle}
\newcommand{\TBTVPQ}{\langle \TTVPQ \rangle}
\newcommand{\TBTVQR}{\langle \TTVQR \rangle}
\newcommand{\Tstrength}{\textit s}
\newcommand{\Tconf}{\textit c}

% Commands for symbolic mathematical notations
\newcommand{\sat}{\mathcal{Sat}}
\newcommand{\prob}{\mathcal{Pr}}
\newcommand{\limp}{\rightarrow}
\newcommand{\lpreimp}[1]{\leadsto^{#1}}
\newcommand{\lseqor}[1]{\bigslopedvee^{#1}}
\newcommand{\lseqand}[1]{\bigslopedwedge^{#1}}
\newcommand{\ldo}[1]{\widehat{#1}}
\newcommand{\llag}[2]{\overrightarrow{#1}^{#2}}
\newcommand{\llead}[2]{\overleftarrow{#1}^{#2}}
%% TODO: try to replace over right arrow by over right harp, etc
%% \newcommand{\llag}[2]{\accentset{\overrightharp}{#1}^{#2}}
%% \newcommand{\llead}[2]{\overleftharp{#1}^{#2}}

\newcommand{\ltrue}{\top}
\newcommand{\lfalse}{\bottom}

\begin{document}
%
\title{Probabilistic Logic Networks for Temporal and Procedural
  Reasoning}

%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Nil Geisweiller
  %\orcidID{0000-0001-5041-6299}
  \and Hedra Yusuf}
%
\authorrunning{N. Geisweiller et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{ SingularityNET Foundation, The
  Netherlands\\ \email{\{nil,hedra\}@singularitynet.io}}
%
\maketitle              % typeset the header of the contribution
%

\begin{abstract}
  TODO

  \keywords{Temporal Reasoning \and Procedural Reasoning \and
    Probabilistic Logic Networks \and OpenCog}
\end{abstract}

\section{Introduction}
\label{sec:intro}
This paper builds upon the Chapter 14 of the Probabilistic Logic
Networks book~\cite{Goertzel09PLN}, adding and modifying definitions
along the way to provide, we believe, better foundations for carrying
temporal and procedural reasoning with PLN.  As we have found, even
though that chapter is well written and conveys the conceptual ideas
with clarity, it leaves some definitions out, or describe them too
informally to serve as solid foundations.  In addition, the Event
Calculus~\cite{Shanahan2000} is mixed with the definitions of
sequential connectors in, what we consider to be, a somewhat arbitrary
and inflexible manner.  On the contrary, here we leave the Event
calculus aside, with the intention to re-introduce it in the future as
a separate layer standing on top of the new definitions.

Although that paper is theoretical, the work presented here is
motivated by the practical need to perform procedural reasoning for
controlling intelligent agents in uncertain environments.

% The goal of this project is to make an agent as rational as possible,
% not necessarily as efficient as possible.  This stems from the concern
% that in order to autonomously gain efficiency the agent must first be
% able to make the best possible decisions, starting first in the outer
% world, and then in the inner world.

% Inner actions could be as transitory as bringing a piece of
% knowledge to the attentional focus, and as profound as rewriting a
% part of its code, like a Goedel Machine.  The atomspace can be
% viewed as a very compact representation of an envelop over
% environments (cite partial operator induction paper).  And PLN can
% be viewed as an abstract-enabling way to calculate the cumulative
% reward (in case it is used as a re-inforcement learner) to be
% maximized, or a goal driven agent in a more general case.  For these
% reasons ROCCA may well be seen as an approximated combination of
% AI\Xi and a Goedel Machine.

% The paper presents

% The agent starts in a completely unknown environment

% The idea is that reasoning is used at all levels, discovering patterns
% from raw observations, building plans and making decisions.

% It is a work in progress.

% Neural networks are excellent at interpolation, but are rather poor at
% extrapolation, what we need for true intelligence is a system that
% thinks critically.

% Rarely do causes and effects take place over arbitrary temporal
% scales.  For instance it is unlikely to find a cause that may produce
% the same effect, or an effect at all, after 1ms, 1 century or any time
% in between.  For that reason we focus on a real time temporal logic.

% \section{Related Work}

% TODO: Event Calculus.  Temporal Logic (Next operator).  and
% evidence-based subjective logic.

% \section{Contributions}

% The contributions of this paper are:
% \begin{enumerate}
% \item Build upon existing temporal reasoning framework defined in
%   Chap.14 [TODO: cite PLN book].
% \item Design an architecture for controlling an agent based on that
%   temporal reasoning extension.
% \end{enumerate}

% \section{Outline}

% \begin{enumerate}
% \item Temporal reasoning
% \end{enumerate}

\section{Probabilistic Logic Networks Recall}
\label{sec:recall}
PLN stands for \emph{Probabilistic Logic
  Networks}~\cite{Goertzel09PLN}.  It is a mixture of predicate and
term logic that has been probabilitized to handle uncertainty.  It has
at least two types of rules for inferring relationships
\begin{enumerate}
\item from direct evidence,
\item from existing relationships.
\end{enumerate}
As such it is well suited for building a model of an environment, and
planning in it.  All it needs is to be properly equipped with a
vocabulary for representing temporal and procedural knowledge.
% The
% Chapter 14 of the PLN book~\cite{Goertzel09PLN} does that.
% However,
% we have found that some definitions are ambiguous, incorrect or
% incomplete.  This paper has been written to remedy that.

\subsection{Elementary Notions}

%% Let us first recall the minimum portion of PLN we will need to
%% describe the temporal logic used in this paper.

% ==========================================
%
% Random field => spatial reasoning
% Stochastic process => temporal reasoning
% |-
% Temporal index = any total order
% Spacial index = any topology
%
% TODO: express Allen's interval relations into TPLN
%
% ==========================================

% TODO: discuss emerging temporal reasoning from non temporal reasoning

Graphically speaking, PLN statements are
sub-hypergraphs\footnote{because links can point to links, not just
  nodes} made of \emph{Links} and \emph{Nodes}, called \emph{Atoms},
decorated with \emph{Truth Values}.  Syntactically speaking, PLN
statements are not very different from statements expressed in another
logic, except that they are usually formatted in prefixed-operator
with a tree-style indentation to emphasize their graphical nature and
to leave room for their truth values.  For instance
$$
\begin{array}{l}
  \TImpl\ \TBTV\\
  \SP P\\
  \SP Q\\
\end{array}
$$
represents an implication link between $P$ and $Q$ with truth value
$\TTV$.  For the sake of conciseness we also introduce the following
notations.  First, we adopt a flattened, as opposed to a tree-style,
representation.  For instance the implication link above is
represented as
$$\TImpl(P, Q)\ \TBTV$$
Second, we introduce a more mathematically looking symbolic
representation.  For instance, that same implication can be
represented as
$$P \limp Q \measeq \TTV$$

There is a large variety of constructs for PLN.  Here, we will focus
primarily on the ones for handling predicates.  Let us recall that
predicates are functions that output Boolean values.  The domain of a
predicate can be arbitrarily defined, but its range is always Boolean.
% TODO In this paper, the capital letters $A$, $B$, $C$ represent atoms of
In this paper, the letters $a$, $b$, $c$ represent atoms of
% any type, $X$, $Y$, $Z$ represent atoms that are variables, while $P$,
any type, $x$, $y$, $z$ represent atoms that are variables, while the
capital letter $P$, $Q$, $R$ represent atoms that are predicates,
typed as follows:
% $$P, Q, R, \hdots: \TAtom^n \mapsto \{\TTrue, \TFalse\}$$
$$P, Q, R, \hdots: \textit{Domain} \mapsto \{\TTrue, \TFalse\}$$
Note that in PLN, predicates are not necessarily crisp because their
outputs can be totally or partially unknown, thus potentially measured
by probabilities.

Truth values are, in essence, second order probability distributions,
or probabilities of probabilities.  They are often described by two
numbers: a strength, $s$, representing a probability, and a
confidence, $c$, representing the confidence over that probability.
Such truth values are called \emph{Simple Truth Values} and are
denoted as follows
$$<\!s, c\!>$$
Alternatively, the strength and the confidence of a simple truth value
$\TTV$ can be denoted $\TTV.s$ and $\TTV.c$ respectively.  Underneath,
a simple truth value is a beta distribution~\cite{Abourizk94Fitting},
similarly to an \emph{opinion} in Subjective Logic~\cite{Josang2026}.
The parameters of the corresponding beta distribution can be obtained
as follows
$$\alpha(s, c)=\alpha_0 + \frac{s.c.k}{1-c}\ \ \ \ \ \ \ \ \ \ \
\beta(s, c)=\beta_0 + \frac{(1-s).c.k}{1-c}$$ where $k$ is a PLN
parameter called the \emph{Lookahead}, and $\alpha_0$ and $\beta_0$
are usually set to 0.5 corresponding to Jeffreys prior.  For truth
values obtained from direct evidence, a simple truth value makes
perfect theoretical sense.  For truth values obtained from indirect
evidence, not so much, even though they are often used in practice.
When more precision is needed, to represent a multi-modal truth value
for instance, a mixture of simple truth values can be used.  Through
out the paper, sometimes we may say \emph{probability}, while what we
mean is \emph{second order probability distribution}.

% TODO: cite Subjective Logic and Chapt 4 of the PLN book.

% The constructs of interest covered in this paper are
% \begin{enumerate}
% \item $\TEval$ which can be used to define predicates from instances.
% \item $\TLamb$ which can be used to define predicates using
%   operational definitions.
% \item $\TAnd$, $\TOr$ and $\TNot$ which are pointwise counterparts of
%   the usual logical connectors.
% \item $\TImpl$ which can be used to define conditional predicates,
%   where their truth values represent conditional probabilities.
% \end{enumerate}

Below is a table of the constructs used in this paper with their
flattened and symbolic representations, as well as precedence values
to minimize parenthesis usage with the symbolic representation.
\renewcommand{\arraystretch}{1.5}
$$
\begin{array}{|c|c|c|}
  \hline
  \text{Flattened} & \text{Symbolic} & \text{Precedence} \\
  \hline
  % \TEval(P, \TList(X_1, \dots, X_n)) & P(X_1, \dots, X_n) & 0 \\
  \TEval(P, a) & P(a) & 0 \\
  % \TEval(P, \TList(X_1, \dots, X_n)) & P(X_1, \dots, X_n)=True & 0 \\
  \TNot(P) & \lnot P & 1 \\
  \TAnd(P, Q) & P \land Q & 2 \\
  \TOr(P, Q) & P \lor Q & 2 \\
  \TImpl(P, Q) & P \limp Q & 4 \\
  a \TBTV & a \measeq \TTV & 5 \\
  \hline
\end{array}
$$
\renewcommand{\arraystretch}{1}

For representing n-ary predicates evaluations we use
$P(a_1, \dots, a_n)$ which may simply be understood as a unary
predicate evaluation applied to a tuple.  Let us now explain their
semantics and how their truth values are to be interpreted.
% The following uses unary predicates, n-ary predicates
% may be understood as unary predicates applied on tuples.
% especially as they each of them below with their corresponding truth
% values
% Let us present these operators below, corresponding to the minimum
% subset we will need in the rest of the paper.
\begin{itemize}
\item $\lnot P$ is the predicate resulting from the pointwise negation
  of $P$.
  % Negation:
  % $$
  % \begin{array}{l}
  %   \TNot\ \TBTV\\
  %   \SP P\\
  % \end{array}
  % $$
  % represents the negation of $P$, or equivalently the indicator
  % function corresponding to the complement of the satisfying set of
  % $P$. The truth value $\TTV$ then represents an estimate of
  % the probability $\prob(\neg P)$ of the negation of $P$.
\item
  % Conjunction:
  % $$
  % \begin{array}{l}
  %   \TAnd\ \TBTV\\
  %   \SP P\\
  %   \SP Q\\
  % \end{array}
  % $$
  $P \land Q$ is the predicate resulting from the pointwise
  conjunction of $P$ and $Q$.
  % , or equivalently the indicator function
  % corresponding to the intersection of the \emph{satisfying sets} of
  % $P$ and $Q$.  The truth value $\TTV$ then represents an estimate of
  % the probability $\prob(P,Q)$ of the conjunction of $P$ and $Q$.
\item
  % Conjunction:
  % $$
  % \begin{array}{l}
  %   \TAnd\ \TBTV\\
  %   \SP P\\
  %   \SP Q\\
  % \end{array}
  % $$
  $P \lor Q$ is the predicate resulting from the pointwise disjunction
  of $P$ and $Q$.
  % , or equivalently the indicator function
  % corresponding to the intersection of the \emph{satisfying sets} of
  % $P$ and $Q$.  The truth value $\TTV$ then represents an estimate of
  % the probability $\prob(P,Q)$ of the conjunction of $P$ and $Q$.
\item $P(a) \measeq \TTV$ states that $P(a)$ outputs $\TTrue$ with a
  second order probability measured by $\TTV$.
  % Evaluation:
  % $$
  % \begin{array}{l}
  %   \TEval\ \TBTV\\
  %   \SP P\\
  %   \SP E\\
  % \end{array}
  % $$
  % states that $P(E)$ outputs $\TTrue$ to a degree set by the truth value
  % $\TTV$.
% \item Lambda:
%   $$
%   \begin{array}{l}
%     \TLamb\ \TBTV\\
%     \SP x\\
%     \SP P(x)\\
%   \end{array}
%   $$
%   is a predicate constructor with variable $x$ and predicate body
%   $P(x)$, where the true value $\TTV$ corresponds to the probability
%   $\prob(P)$ of $P(x)$ to output $\TTrue$ for a random input.
\item
  % Implication:
  % $$
  % \begin{array}{l}
  %   \TImpl\ \TBTV\\
  %   \SP P\\
  %   \SP Q\\
  % \end{array}
  % $$
  $P \limp Q \measeq \TTV$ states that if $P(a)$ is $\TTrue$ for some
  $a$ in the domain of $P$, then $Q(a)$ is $\TTrue$ with a second
  order probability measured by $\TTV$.  In simple probability terms,
  it represents $\prob(Q|P)$~\footnote{To be precise, $\prob(Q|P)$
    should be understood as $\prob(\sat(Q)|\sat(P))$, where $\sat(P)$
    and $\sat(Q)$ are the satisfying sets of $P$ and $Q$
    respectively.}, the conditional probability of $Q$ knowing $P$.
  We may also say that such implication is a conditional predicate
  where $Q$ is conditioned by $P$.  Also, $P$ may be referred as the
  \emph{implicant} and $Q$ may be referred as the \emph{implicand}.
  % represents the predicate $Q$ conditioned on $P$, that is
  % only defined for instances $x$ for which $P(x)$ is $\TTrue$.  The
  % truth value $\TTV$ then represents an estimate of the conditional
  % probability $\prob(Q|P)$.  There is some subtleties to take into
  % account due to the fact $P(x)$ can actually be partially true
  % (stated by the truth values of $\TEval$ links as explained above),
  % but this resolves nicely by assuming degrees of truth are
  % probabilistic.  More is explained about that below.
\item $P \measeq \TTV$ states that the prevalence of $P$ being
  $\TTrue$ is measured by $\TTV$.
  % It is
  % equivalent to $\mathbb{True} \limp P \measeq \TTV$ where
  % $\mathbb{True}$ is the predicate that is $\TTrue$ for any input.
\end{itemize}

\subsection{Inference Rules}
Inferences rules are used to construct PLN statements and calculate
their truth values.  They fall into two groups, direct evidence based
or otherwise.  Rules from the former group infer abstract knowledge
from direct evidence, while rules from the latter group infer
knowledge by combining existing abstractions.  There are dozens of
inference rules, for now we only recall two, \emph{Implication Direct
  Introduction} and \emph{Deduction}.

\subsubsection{The Implication Direct Introduction Rule (IDI)} takes
evaluations
% $\TEval$
% links
as premises and produces an implication as conclusion.  It is formally
depicted by the following proof tree
% {\scriptsize
% \begin{prooftree}
%   \AxiomC{$
%     \begin{array}{l}
%       \TEval\ \TBTVPi\\
%       \SP P\\
%       \SP E_i\\
%     \end{array}
%     $}
%   \AxiomC{$\hdots$}
%   \AxiomC{$
%     \begin{array}{l}
%       \TEval\ \TBTVQi\\
%       \SP Q\\
%       \SP E_i\\
%     \end{array}
%     $}
%   \RightLabel{(IDI)}
%   \TrinaryInfC{$
%     \begin{array}{l}
%       \TImpl\ \TBTV\\
%       \SP P\\
%       \SP Q\\
%     \end{array}
%     $}
% \end{prooftree}}
{\small
\begin{prooftree}
  \AxiomC{$P(a_1) \measeq \TTVPo$}
  \AxiomC{$Q(a_1) \measeq \TTVQo$}
  \AxiomC{$\hdots$}
  \AxiomC{$P(a_n) \measeq \TTVPn$}
  \AxiomC{$Q(a_n) \measeq \TTVQn$}
  \RightLabel{(IDI)}
  \QuinaryInfC{$P\limp Q \measeq \TTV$}
\end{prooftree}}
\noindent Assuming perfectly reliable direct evidence\footnote{A
  perfectly reliable piece of evidence has a confidence of 1.  Dealing
  with unreliable evidence involves using convolution products and is
  outside of the scope of this paper.}  then the resulting simple
truth value can be calculated as follows
$$\TTV.\Tstrength = \frac{\sum_{i=1}^n f_\wedge(\TTVPi.\Tstrength,
  \TTVQi.\Tstrength)}{\sum_{i=1}^n \TTVPi.\Tstrength}\ \ \ \ \ \ \ \ \
\ \ \ \ \ \TTV.\Tconf = \frac{n}{n+k}$$
where % $\TTV.\Tstrength$ and
% $\TTV.\Tconf$ respectively represent the strength and the confidence
% of $\TTV$, $k$ is the lookahead, and
$f_\wedge$ is a function embodying a probabilistic assumption about
the conjunction of the events.  Such function typically ranges from
the product (perfect independence) to the $\min$ (perfect overlap).
Note that this inference rule takes an arbitrary number of premises.
In practice it is not a problem as it is decomposed into two rules
covering the base and the recursive cases, while storing evidence to
avoid double counting.

\subsubsection{The Deduction Rule (D)} takes two implications as
premises and produces a third one.  Depending on the assumptions made
there exists different variations of that rule.  The simplest one is
based on the Markov property % assuming that the probability of $R$
% knowing $P$ and $Q$ equals to the probability of $R$ knowing only $Q$.
$$\prob(R|Q,P) = \prob(R|Q)$$
%% $$\prob(R|\neg Q,P) = \prob(R|\neg Q)$$
which gives rise to the rule depicted by the following proof tree
{\small
  \begin{prooftree}
    \AxiomC{$P \limp Q \measeq \TTVPQ$}
    \AxiomC{$Q \limp R \measeq \TTVQR$}
    \AxiomC{$P \measeq \TTVP$}
    \AxiomC{$Q \measeq \TTVQ$}
    \AxiomC{$R \measeq \TTVR$}
    \RightLabel{(D)}
    \QuinaryInfC{$P \limp R \measeq \TTV$}
  \end{prooftree}
}
%%  essentially expressing a probabilitized version of the transitivity
%% of $\TImpl$ with a Markov property
%% $$\prob(R|Q,P) = \prob(R|Q)$$
%% $$\prob(R|\neg Q,P) = \prob(R|\neg Q)$$
\noindent The reader may notice that three additional premises have
been added, corresponding to the probabilities $\prob(P)$, $\prob(Q)$
and $\prob(R)$.  This is a consequence of the Markov property.  The
exact formula for that variation is not recalled here but it merely
derives from
$$\prob(R|P) = \prob(R|Q,P)\times\prob(Q|P) + \prob(R|\neg
Q,P)\times\prob(\neg Q|P)$$ More information about this derivation can
be found in Chapter 5, Section 5.3 of~\cite{Goertzel09PLN}.  Finally,
one may notice that the same conclusion may be inferred by different
inference paths leading to different truth values.  How to properly
aggregate these truth values is not the subject of this paper and is
discussed in Chapter 5, Section 5.10 of~\cite{Goertzel09PLN}.

\section{Temporal Probabilistic Logic Networks}
\label{sec:temporal}
A temporal extension of PLN is defined in Chapter 14
of~\cite{Goertzel09PLN}.  However, we have found that some definitions
are ambiguous, incorrect or incomplete.  In that section we provide a
possible interpretation and completion of such temporal extension.
%% , showing how the two inference rules recalled
%% above to carry out temporal reasoning.  Let us define that
Let us begin by defining \emph{Temporal Predicates}, also called
\emph{Fluents}, that are regular predicates equipped with a temporal
dimension
$$P, Q, R, \hdots: \textit{Domain} \times \TTime \mapsto \{\TTrue,
\TFalse\}$$
\noindent The type of the temporal dimension, $\TTime$, could in
principle be any thing that has a minimum set of requirements, such as
being an ordered semigroup or such.  In practice so far, we have used
integers instead, thus capturing a discrete notion of time.  Not all
temporal predicates need to have a non-temporal domain, denoted
$\textit{Domain}$.  In that case, we may simply assume that such
domain is the unit type $()$ and ignore it.

\subsection{Temporal Operators}
Let us define a set of temporal operators operating over temporal
predicates.

\subsubsection{$\TLag$ and $\TLead$} are temporal operators to shift
the temporal dimension of a temporal predicate.  They are similar to
the metric variations, $P_n$ and $F_n$, of the \emph{Past} and
\emph{Future} operators of Tense Logic~\cite{Prior1967}, with the
distinction that they are applied over temporal predicates, as opposed
to Boolean modal expressions.  The $\TLag$ operator is formally
defined as follows
% $$Lag(P, T) := Lambda(VariableList(x, t), P(x, t-T))$$
$$Lag(P, T) := \lambda x, t. P(x, t-T)$$
% where the first line of the $\TLamb$ link is the variable
% declaration of the temporal predicate and the second line is the body
% representing a temporally shifted reconstruction of $P$.
Meaning, given a temporal predicate $P$, it builds a temporal
predicate shifted to the right by $T$ time units.  In order words, it
allows to looks into the past, or one may say that it brings the past
into the present.
% This is a major difference with \cite{PLN}
% that defined sequential and using notions of the Event Calculus
% \cite{TODO}.  Here we do not do that (TODO: maybe such operator should
% be called PrecedeAnd, or such).  That is because using this simpler
% notion of sequential and allows more flexibility to construct various
% forms of descriptions of how events initialization, termination, etc,
% are sequenced.
The $\TLead$ operator is the inverse of the $\TLag$ operator, thus
$$Lead(Lag(P, T), T) \equiv P$$
and is formally defined as follows
$$Lead(P, T) := \lambda x, t. P(x, t+T)$$
It allows to look into the future, or one may say that it brings the
future into the present.

\subsubsection{$\TSeqAnd$} is a temporal conjunction where one of the
temporal predicate arguments have been temporally shifted.  There are
at least two variations that can be defined.  A first where the past
of the first predicate is brought into the present.  A second where
the future of the second predicate is brought into the present.  In
this paper we use the second one, formally defined as
$$\TSeqAnd(T, P, Q) := \TAnd(P, \TLead(Q, T))$$
which results into a temporal predicate that is $\TTrue$ at time $t$
if and only if $P$ is $\TTrue$ at time $t$ and $Q$ is $\TTrue$ at time
$t+T$.  Since we do not know at that point which one of the two
variations is best, in practice we have implemented both, but in that
paper we settle to one for the sake of simplicity.
% There are two variations one can define.  The $\TBSeqAnd$ where the
% past of the first temporal predicate is brought into the present,
% using the $\TLag$ operator, formally defined as
% $$\TBSeqAnd(T, P, Q) := \TAnd(Lag(P, T), Q)$$
% resulting into a temporal predicate that is $\TTrue$ at time $t$ if
% and only if $P$ is $\TTrue$ at time $t-T$ and $Q$ is $\TTrue$ at time
% $t$.  The other variation is the $\TFSeqAnd$ where the future of the
% second temporal predicate is brought into the present, formally
% defined as
% $$\TFSeqAnd(T, P, Q) := \TAnd(P, \TLead(Q, T))$$
% resulting into a temporal predicate that is $\TTrue$ at time $t$ if
% and only if $P$ is $\TTrue$ at time $t$ and $Q$ is $\TTrue$ at time
% $t$.  For now we settle with the second variation, that is $\TSeqAnd$
% is defined as $\TFSeqAnd$ for the rest of the paper.
% ~\footnote{In the
%   code however we have not
% made such commitment and have implemented both variations.
% Finally one may notice that $\TBSeqAnd$ and $\TFSeqAnd$ equivalent up
% to temporal shifting, as follows

% NEXT
% $$
% \begin{array}{l}
%   \TBSeqAnd\\
%   \SP T\\
%   \SP P\\
%   \SP Q\\
% \end{array}
% \equiv
% \begin{array}{l}
%   \TBSeqAnd\\
%   \SP T\\
%   \SP P\\
%   \SP Q\\
% \end{array}
% $$

\subsubsection{$\TSeqOr$} is a temporal disjunction where one of the
temporal predicate arguments have been temporally shifted.  Like for
$\TSeqAnd$ we settle to the variation where the future of the second
predicate is brought into the present, defined as
$$\TSeqOr(T, P, Q) := \TOr(P, \TLead(Q, T))$$
which results into a temporal predicate that is $\TTrue$ at time $t$
if and only if $P$ is $\TTrue$ at time $t$ or $Q$ is $\TTrue$ at time
$t+T$.

\subsubsection{$\TPredImpl$} is an implication where the future of the
implicand has been brought into the present, defined as
$$\TPredImpl(T, P, Q) := \TImpl(P, \TLead(Q, T))$$
resulting into a conditional predicate, that in order to be defined at
time $t$ requires that $P$ is $\TTrue$ at time $t$, and if so, is
$\TTrue$ at $t$ if and only if $Q$ is $\TTrue$ at time $t+T$.\\

Let us introduce a symbolic representation for these temporal
constructs with precedence values to minimize parenthesis usage.
% We now have everything we need to define
% temporal inference rules, but before that let us first introduce some
% notations in order to be easier to lay out.

% \subsection{Notations}

% The following notations can afford to ignore truth values, that is
% because no new formula is required for temporal reasoning.  All that
% is required are the definitions above mapping temporal expressions
% into equivalent atemporal ones.  The notations are summarized in the
% table below, ranked by syntactic precedence to minimize the number of
% required parenthesis.
\renewcommand{\arraystretch}{1.5}
$$
\begin{array}{|c|c|c|}
  \hline
  \text{Flattened} & \text{Symbolic} & \text{Precedence} \\
  \hline
  % \TEval(P, \TList(X_1, \dots, X_n)) & P(X_1, \dots, X_n) & 1 \\
  % \TLamb(t, \TAtTime(\TExec(A), t)) & \ldo{A} & 1 \\
  \TLag(P, T) & \llag{P}{T} & 1 \\
  \TLead(P, T) & \llead{P}{T} & 1 \\
  % \TAnd(P, Q) & P \land Q & 2 \\
  % \TOr(P, Q) & P \lor Q & 2 \\
  \TSeqAnd(T, P, Q) & P \lseqand{T} Q & 3 \\
  \TSeqOr(T, P, Q) & P \lseqor{T} Q & 3 \\
  % \TImpl(P, Q) & P \limp Q & 4 \\
  \TPredImpl(T, P, Q) & P \lpreimp{T} \! \! Q & 4 \\
  % \TPredImpl(T, P, Q) & P \lpreimp{T} \! \! Q & 4 \\
  \hline
\end{array}
$$
\renewcommand{\arraystretch}{1}

The $\TLag$ (resp. $\TLead$) operator is symbolized by an overlined
arrow going to the right (resp. to the left) because it brings the
past (resp. the future) into the present.

% In addition
% The precedence of everything else (predicates nodes, etc) is 0.

%% Note that, assuming a ForeSequentialAnd, whether it is right or left
%% associative, changes whether the lag should be cumulative or not.
%%
%% Right-associative:
%% C∧A₁≺ᵀA₂≺ᵁA₃
%% C∧A₁≺ᵀ(A₂≺ᵁA₃)
%% C∧A₁∧Lead(A₂≺ᵁA₃, T)
%% C∧A₁∧Lead(A₂∧Lead(A₃, U), T)
%% C∧A₁∧Lead(A₂,T)∧Lead(A₃,T+U)
%%
%% Left-associative:
%% C∧A₁≺ᵀA₂≺ᵁA₃
%% (C∧A₁≺ᵀA₂)≺ᵁA₃
%% C∧A₁∧Lead(A₂,T)≺ᵁA₃
%% C∧A₁∧Lead(A₂,T)∧Lead(A₃,U)
%%
%% Assuming a BackSequentialAnd, it is the opposite

% For instance

%% $$
%% \begin{array}{l}
%%   \TPredImpl\ \TBTV\\
%%   \SP \TSeqAnd\\
%%   \SP
%%   \SP E\\
%% \end{array}
%% $$

% TODO: show examples of notational format with the effect of precedence

\subsection{Temporal Rules}
Given these operators we can now introduce a number of temporal
inference rules.

\subsubsection{The Predictive Implication to Implication Rule (PI)}
takes a predictive implication as premise and produces an equivalent
implication, as depicted by the following proof tree.
{\small
\begin{prooftree}
  \AxiomC{$P \lpreimp{T} Q \measeq \TTV$}
  \RightLabel{(PI)}
  \UnaryInfC{$P \limp \llead{Q}{T} \measeq \TTV$}
\end{prooftree}}
\noindent Note that because the conclusion is equivalent to the
premise, the truth values may optionally be stripped from the rule
while remaining valid.  {\small
\begin{prooftree}
  \AxiomC{$P \lpreimp{T} Q$}
  \RightLabel{(PI)}
  \UnaryInfC{$P \limp \llead{Q}{T}$}
\end{prooftree}}
% \noindent Note that because the conclusion is equivalent to the
% premise, the truth values do not need to be indicated in the rule
% definition.
% \noindent When the formula for calculating the resulting truth value
% is the identity function, or is obvious in the current context, we may
% simplify the rule definition by ignoring the truth values.  For
% instance the PI inference rule may be defined as
% {\small
% \begin{prooftree}
%   \AxiomC{$P \lpreimp{T} Q$}
%   \RightLabel{(PI)}
%   \UnaryInfC{$P \limp \llead{Q}{T}$}
% \end{prooftree}}

\subsubsection{The Implication to Predictive Implication Rule (IP)}
takes an implication as premise and produces an equivalent predictive
implication, as depicted, here without truth value, by the following
proof tree. {\small
\begin{prooftree}
  \AxiomC{$P \limp \llead{Q}{T}$}
  \RightLabel{(IP)}
  \UnaryInfC{$P \lpreimp{T} Q$}
\end{prooftree}}

\subsubsection{The Temporal Shifting Rule (S)} takes a temporal
predicate and shits its temporal dimension to the left or the right.
An example of such rule is depicted by the following proof tree.
{\small
\begin{prooftree}
  \AxiomC{$P \measeq \TTV$}
  \RightLabel{(S)}
  \UnaryInfC{$\llead{P}{T} \measeq \TTV$}
\end{prooftree}}
\noindent Shifting does not change the truth value of the predicate.
Indeed, the prevalence of being $\TTrue$ remains the same, only the
origin of the temporal dimension changes.  Note however that the
predicate itself changes, it is shifted.  Therefore, unlike for the IP
and PI inference rules that produce equivalent predicates, the truth
values must be included in the rule definition, otherwise the rule of
replacement would incorrectly apply.  There are a number of variations
of that rule.  For the sake of conciseness we will not enumerate them
all, and instead show one more variation over conditional predicates.
{\small
\begin{prooftree}
  \AxiomC{$P \limp Q \measeq \TTV$}
  \RightLabel{(S)}
  \UnaryInfC{$\llead{P}{T} \limp \llead{Q}{T} \measeq \TTV$}
\end{prooftree}}
% \noindent More trivial variations, not provided for the sake of
% conciseness, are used and labeled under the same rule name, Temporal
% Shifting (S).

\subsubsection{The Predictive Implication Direct Introduction Rule
  (PIDI)} is similar to the implication direct introduction rule of
Section~\ref{sec:recall} but accounts for temporal delays between
evaluations.  It is formalized by the following proof tree. {\small
\begin{prooftree}
  \AxiomC{$\left(P(a_i, t_i) \measeq \TTVPi\right)_{i=1, \dots, n}$}
  \AxiomC{$\left(Q(a_i, t_i+T) \measeq \TTVQi\right)_{i=1, \dots, n}$}
  \RightLabel{(PIDI)}
  \BinaryInfC{$P \lpreimp{T} Q \measeq \TTV$}
\end{prooftree}}
\noindent The truth value formula is identical to that of the
implication direct introduction rule.  In fact, such rule can be
trivially derived by combining the implication direct introduction
rule, the implication to predictive implication rule and the
definition of the $\TLead$ operator.

\subsubsection{The Temporal Deduction Rule (TD)} is similar to the
deduction rule of Section~\ref{sec:recall} but operates on predictive
implications.  It is formally depicted by the following proof tree.
{\scriptsize
  \begin{prooftree}
    \AxiomC{$P \lpreimp{T_1} Q \measeq \TTVPQ$}
    \AxiomC{$Q \lpreimp{T_2} R \measeq \TTVQR$}
    \AxiomC{$P \measeq \TTVP$}
    \AxiomC{$Q \measeq \TTVQ$}
    \AxiomC{$R \measeq \TTVR$}
    \RightLabel{(TD)}
    \QuinaryInfC{$P \lpreimp{T_1+T_2} R \measeq \TTV$}
  \end{prooftree}
}
\noindent As it turns out, the truth value formula is also identical
to that of the deduction rule, but the proof is not so trivial.
% as in
% the case of the predictive implication direct introduction rule.
% and the most important one Temporal Deduction (TD)
% {\small
%   \begin{prooftree}
%     \AxiomC{$P \lpreimp{T_1} Q$}
%     \AxiomC{$Q \lpreimp{T_2} R$}
%     \AxiomC{$P$}
%     \AxiomC{$Q$}
%     \AxiomC{$R$}
%     \RightLabel{(TD)}
%     \QuinaryInfC{$P \lpreimp{T_1+T_2} R$}
%   \end{prooftree}
% }
In order to convince us that it is the case, let us construct a proof
tree that can perform the same inference without requiring the
temporal deduction rule.  The result is depicted below
% NEXT To determine the formula to calculate the resulting truth value of
% such rule, we only need to map such temporal deduction into a regular
% deduction as follows
{\tiny
  \begin{prooftree}
    \AxiomC{$P \lpreimp{T_1} Q \measeq \TTVPQ $}
    \RightLabel{(PI)}
    \UnaryInfC{$P \limp \llead{Q}{T_1} \measeq \TTVPQ$}
    \AxiomC{$Q \lpreimp{T_2} R \measeq \TTVQR$}
    \RightLabel{(PI)}
    \UnaryInfC{$Q \limp \llead{R}{T_2} \measeq \TTVQR$}
    \RightLabel{(S)}
    \UnaryInfC{$\llead{Q}{T_1} \limp \llead{R}{T_1+T_2} \measeq \TTVQR$}
    \AxiomC{$\!\!\!\!\!\!P \measeq \TTVP\!\!\!\!\!\!$}
    \AxiomC{$Q \measeq \TTVQ$}
    \RightLabel{(S)}
    \UnaryInfC{$\llead{Q}{T_1} \measeq \TTVQ$}
    \AxiomC{$R \measeq \TTVR$}
    \RightLabel{(S)}
    \UnaryInfC{$\llead{R}{T_1+T_2} \measeq \TTVR$}
    \RightLabel{(D)}
    \QuinaryInfC{$P \limp \llead{R}{T_1+T_2} \measeq \TTV$}
    \RightLabel{(IP)}
    \UnaryInfC{$P \lpreimp{T_1+T_2} R \measeq \TTV$}
  \end{prooftree}}
\noindent As you may see, the premises and the conclusion of that
inference tree match exactly the premises and the conclusion of the
temporal deduction rule.  Since none of the intermediary formulae,
beside the deduction formula, alter the truth values, we may conclude
that the formula of the temporal deduction rule is identical to that
of the deduction rule.

\subsection{Examples of Temporal PLN in Action}
In this section, we will demonstrate how to perform temporal deduction using Predictive Implication Direct Introduction (PIDI) rule to discover implications from existing evaluations and then combine them with background knowledge. To illustrate this process, we consider predicates $P$ and $Q$, along with their evaluations on data points: $a$ and $b$. The following proof tree shows how we apply the PIDI rule

{\tiny
\begin{prooftree}
  \AxiomC{$P(a, t) \measeq \TTVP_a$}
  \AxiomC{$P(b, t) \measeq \TTVP_b$}
  \AxiomC{$Q(a, t + T) \measeq \TTVQ_a$}
  \AxiomC{$Q(b, t + T) \measeq \TTVP_b$}
  \RightLabel{(PIDI)}
  \QuaternaryInfC{$P \lpreimp{T_1} Q \measeq \TTV$}
\end{prooftree}}

\noindent Assuming we have prior knowledge of $Q \lpreimp{T_2} R$
, we can use the output of the above rule and do temporal deduction as
{\tiny
\begin{prooftree}
  \AxiomC{$P \lpreimp{T_1} Q \measeq \TTVPQ$}
  \AxiomC{$Q \lpreimp{T_2} R \measeq \TTVQR$}
  \AxiomC{$P \measeq \TTVP$}
  \AxiomC{$Q \measeq \TTVQ$}
  \AxiomC{$R \measeq \TTVR$}
  \RightLabel{(TD)}
  \QuinaryInfC{$P \lpreimp{T_1+T_2} R \measeq \TTV$}
\end{prooftree}}

\noindent We can also have another example involving actions. Let's say we have prior knowledge of $Q\!\land\!\ldo{A}\lpreimp{T_2} R$, the complete proof tree becomes 

% P↝ᵀ¹Q
% (Q∧A)↝ᵀ²R
% ⊢
% (P⩘ᵀ¹A)↝ᵀ²R

{\tiny
\begin{prooftree}
  \AxiomC{$P(a, t) \measeq \TTVP_a \hspace{0.2cm} 
  		P(b, t) \measeq \TTVP_b \hspace{0.2cm} 
  		Q(a, t + T_1) \measeq \TTVQ_a \hspace{0.2cm}
  		Q(b, t + T_1) \measeq \TTVP_b$}
  \RightLabel{(PIDI)}
  \UnaryInfC{$P \lpreimp{T_1} Q \measeq \TTV$}
  \AxiomC{$Q\!\land\!\ldo{A}\lpreimp{T_2} R \measeq \TTVQR \hspace{0.2cm} 
  		P \measeq \TTVP \hspace{0.2cm}
  		Q \measeq \TTVQ \hspace{0.2cm}
  		R \measeq \TTVR$}
  \RightLabel{(TD)}
  \BinaryInfC{$P\!\lseqand{T_1}\!\ldo{A} \lpreimp{T_2} R \measeq \TTV$}
\end{prooftree}}

\noindent In both cases, we were able to arrive at a conclusion that $\TImpl(P, R)$ with the required temporal information to distinguish between scenarios with and without the execution of action $A$.

\section{Procedural Reasoning}
\label{sec:procedural}
Let us now examine how to use temporal deduction to perform a special
type of procedural reasoning, to build larger plans made of smaller
plans by chaining their actions.  Given plans, also called
\emph{Cognitive Schematics}~\cite{Goertzel2011CSP}, of the form
$$C_1 \land A_1 \lpreimp{T_1} C_2 \measeq \TTVo$$
$$\vdots$$
$$C_n \land A_n \lpreimp{T_n} G \measeq \TTVn$$
expressing that in context $C_i$, executing action $A_i$ may lead to
subgoal $C_{i+1}$ or goal $G$, after $T_i$ time units, with a
likelihood of success measured by $\TTVi$, we show how to infer the
composite plan
$$C_1 \land A_1 \lseqand{T_1} \dots \lseqand{T_{n-1}} A_n
\lpreimp{T_1+\dots+T_n} G \measeq \TTV$$ alongside its truth value
$\TTV$.  The inferred plan expresses that in context $C_1$, executing
actions $A_i$ to $A_n$ in sequence, waiting $T_i$ time units between
$A_i$ and $A_{i+1}$, leads to goal $G$ after $T_1+\dots+T_n$ time
units, with a likelihood of success measured by $\TTV$.  Note that
strictly speaking, $A_i$ is not an action, it is a predicate that
captures the temporal activation of an action.  This can be formalized
in PLN as well but is not where the difficulty lies.  Thus here we
directly work with action activation predicates and refer to them as
actions for the sake of convenience.

% using PLN but that is not  Formally it can be , but
% we allow us the abuse of saying that it is an action.

% Likewise, we can use the same temporal to regular deduction mapping to
% build inference rules for procedural reasoning.  Given two cognitive
% schematics
% $$P \land \ldo{A} \lpreimp{T_1} Q$$
% expressing that executing $A$ in context $P$ likely leads to context
% $Q$ after $T_1$ time units, and
% $$Q \land \ldo{B} \lpreimp{T_2} R$$
% expressing that executing $B$ in context $Q$ likely leads to context
% $R$ after $T_2$ time units, the question becomes how to infer the
% likelihood that executing $A$ and $B$ in sequence starting from
% context $P$ leads to context $R$ after $T_1+T_2$ time units,
% corresponding to the cognitive schematic
% $$P \land \ldo{A} \lseqand{T_1} \ldo{B} \lpreimp{T_1+T_2} R$$

% Using the same rules to map $\TPredImpl$ to regular $\TImpl$ and vice
% versa, as well as rules about the $\TLead$ operator, we can construct
% the following inference tree, in fact the PLN engine can construct it
% for us

Let us show how to do that with two action plans by building a proof
tree, like we did for the temporal deduction rule.  The final
inference rule we are trying to build should look like
{\small
  \begin{prooftree}
    \AxiomC{$C_1\land A_1 \lpreimp{T_1} C_2 \measeq \TTV^{\ \!12}$}
    \AxiomC{$C_2 \land A_2 \lpreimp{T_2} C_3 \measeq \TTV^{\ \!23}$}
    \AxiomC{$\dots$} %Premises about $C_1$, $C_2$, $A_1$ and $A_2$}
    % \RightLabel{(PD)}
    \TrinaryInfC{$C_1 \land A_1 \lseqand{T_1} A_2 \lpreimp{T_1+T_2}
      C_2 \measeq \TTV$}
  \end{prooftree}}
\noindent where the dots are premises to be filled once we know what
they are.  Indeed, we cannot directly apply temporal deduction because
the implicand of the first premise, $C_2$, does not match the
implicant of the second premise, $C_2\land A_2$.  For that reason it
is unclear what the remaining premises are.  However, we can build an
equivalent proof tree using regular deduction, as well as other
temporal inferences rules defined in Section~\ref{sec:temporal}.  The
resulting tree, without truth values so that it can fit within the
width of the page, is given below. {\tiny
  \begin{prooftree}
    \AxiomC{$C_1\!\land\! A_1 \lpreimp{T_1} C_2$}
    \RightLabel{(PI)}
    \UnaryInfC{$C_1\!\land\! A_1 \limp^{T_1} \llead{C_2}{T_1}$}
    \RightLabel{(I)}
    \UnaryInfC{$C_1\!\land\! A_1\!\land\!\llead{A_2}{T_1} \limp
      \llead{C_2}{T_1}\!\land\!\llead{A_2}{T_1}\!\!\!\!\!\!\!$}
    \AxiomC{$C_2\!\land\!A_2 \lpreimp{T_2} C_3$}
    \RightLabel{(PI)}
    \UnaryInfC{$C_2\!\land\!A_2 \limp \llead{C_3}{T_2}$}
    \RightLabel{(S)}
    \UnaryInfC{$\!\!\!\!\!\!\!\llead{C_2}{T_1}\!\land\!\llead{A_2}{T_1} \limp
      \llead{C_3}{T_1+T_2}\!\!\!\!\!\!\!$}
    \AxiomC{$\!\!\!\!\!\!\!C_1\!\land\! A_1\!\land\!\llead{A_2}{T_1}\!\!\!\!\!\!$}
    \AxiomC{$C_2\!\land\!A_2$}
    \RightLabel{(S)}
    \UnaryInfC{$\!\!\!\!\!\!\!\llead{C_2}{T_1}\!\land\!\llead{A_2}{T_1}\!\!\!\!\!\!\!$}
    \AxiomC{$C_3$}
    \RightLabel{(S)}
    \UnaryInfC{$\!\!\!\!\!\!\!\llead{C_3}{T_1+T_2}\!\!\!\!\!\!\!$}
    \RightLabel{(D)}
    \QuinaryInfC{$C_1\!\land\! A_1\!\land\!\llead{A_2}{T_1} \limp \llead{C_3}{T_1+T_2}$}
    \RightLabel{(IP)}
    \UnaryInfC{$C_1\!\land\! A_1\!\lseqand{T_1}\!A_2 \lpreimp{T_1+T_2} C_3$}
\end{prooftree}}
\noindent Note that we have used of a new rule labeled (I) at the left
of the proof tree.  This rule eliminates independent predicates from
an implication, without modifying the truth value of its conclusion.
Its use is justified by the fact that $A_2$ is executed
immediately \emph{after} reaching $C_2$, thus cannot have an effect on it.\\

After retaining the premises, the conclusion and adding back the truth
values, we obtain the following procedural deduction rule {\scriptsize
  \begin{prooftree}
    \AxiomC{$\!\!\!\!C_1\!\land\! A_1 \lpreimp{T_1} C_2 \measeq \TTV^{\ \!12}\!\!\!\!\!\!\!\!$}
    \AxiomC{$\!\!\!\!\!\!\!C_2\!\land\!A_2 \lpreimp{T_2} C_3 \measeq \TTV^{\ \!23}\!\!\!\!\!\!\!\!$}
    \AxiomC{$\!\!\!\!\!\!\!C_1\!\land\! A_1\!\land\!\llead{A_2}{T_1} \measeq \TTV^{\ \!1}\!\!\!\!\!\!\!\!$}
    \AxiomC{$\!\!\!\!\!\!\!C_2\!\land\!A_2 \measeq \TTV^{\ \!2}\!\!\!\!\!\!\!\!$}
    \AxiomC{$\!\!\!\!\!\!\!C_3 \measeq \TTV^{\ \!3}\!\!\!\!\!\!\!\!\!\!\!$}
    \RightLabel{(PD)}
    \QuinaryInfC{$C_1\!\land\! A_1\!\lseqand{T_1}\!A_2 \lpreimp{T_1+T_2} C_3 \measeq \TTV$}
  \end{prooftree}}
\noindent with a formula identical to that of the deduction rule, once
again.  The premises filling the dots are therefore
$$C_1\!\land\! A_1\!\land\!\llead{A_2}{T_1} \measeq \TTV^{\ \!1} \ \ \
\ \ \ C_2\!\land\!A_2 \measeq \TTV^{\ \!2} \ \ \ \ \ \ \ C_3 \measeq
\TTV^{\ \!3}$$ There is no doubt these premises could be further
decomposed into sub-inferences as it was done with the (I) rule.
Indeed, likely more simplifications can be made by assuming that the
agent has a form of freewill and thus that its actions are independent
of the rest of the universe, outside of its decision policy influenced
by its very procedural reasoning.  This is reminiscent of the
do-calculus~\cite{Pearl1995CausalDF} and will be explored in more
depth in the future.  In the meantime, these are left as they are, as
it introduces no additional assumption, and their truth values can
always be calculated using inference rules based on direct evidence,
if anything else.

% In practice they can
% easily be inferred using inference rules based on direct evidence.

% Indeed, different rules may result in different levels of
% confidence depending on the available knowledge.  For instance, if it
% is known that $C_1$, $A_1$ and $\llead{A_2}{T_1}$ are independent,
% perhaps unlikely but possible, then using an independent-based
% conjunction introduction would be good thing.  Otherwise, if these
% three predicates have already been observed in conjunction, maybe a
% conjunction direct introduction rule would be better, etc.  These are
% difficult decisions to make that should be left to the inference
% engine.

\section{Conclusion}
\label{sec:conclusion}
TODO: implement more temporal and procedural rules, support temporal
intervals, behavior trees, introduce Temporal Truth Value.  Integrate
Event Calculus.

Hint regarding intervals: define a notion of parameterized union,
where for temporal interval the parameters would be temporal variables
ranging over intervals.

%
% ---- Bibliography ----
%
\bibliographystyle{splncs04} \bibliography{local}

\end{document}
